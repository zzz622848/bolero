

.. _sphx_glr_auto_examples_behavior_search_plot_cart_pole.py:


=========
Cart Pole
=========

This is an example of how to use the Cart Pole environment from OpenAI Gym
via the wrapper that is provided with BOLeRo. A linear policy is sufficient
to solve the problem and policy search algorithm usually work very well in
this domain.




.. image:: /auto_examples/behavior_search/images/sphx_glr_plot_cart_pole_001.png
    :align: center


.. rst-class:: sphx-glr-script-out

 Out::

    [33mWARN: gym.spaces.Box autodetected dtype as <type 'numpy.float32'>. Please provide explicit dtype.[0m




|


.. code-block:: python

    print(__doc__)

    import numpy as np
    import matplotlib.pyplot as plt
    from bolero.environment import OpenAiGym
    from bolero.behavior_search import BlackBoxSearch
    from bolero.optimizer import CMAESOptimizer
    from bolero.representation import LinearBehavior
    from bolero.controller import Controller


    beh = LinearBehavior()
    env = OpenAiGym("CartPole-v0", render=False, seed=0)
    opt = CMAESOptimizer(variance=10.0 ** 2, random_state=0)
    bs = BlackBoxSearch(beh, opt)
    controller = Controller(environment=env, behavior_search=bs, n_episodes=300)

    rewards = controller.learn()
    controller.episode_with(bs.get_best_behavior())

    plt.figure()
    ax = plt.subplot(111)
    ax.set_title("Optimization progress")
    ax.plot(rewards)
    ax.set_xlabel("Episode")
    ax.set_ylabel("Reward")
    ax.set_ylim(-10, 210)
    plt.show()

**Total running time of the script:** ( 0 minutes  1.966 seconds)



.. only :: html

 .. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_cart_pole.py <plot_cart_pole.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_cart_pole.ipynb <plot_cart_pole.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
